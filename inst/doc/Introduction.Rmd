---
title: "Introduction to leapgp"
author: "Kellin Rumsey"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to leapgp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(leapgp)
library(RColorBrewer)
library(lhs)
library(laGP)
library(tictoc)
```

In this vignette, we will demonstrate the `leapgp` function and compare it to the `laGP` package. We begin by defining the "twin-galaxies" synthetic computer model. 

```{R}
f1 <- function(x){
  x1 <- x[1]
  x2 <- x[2]

  term1 <- (5/2)*x1 - (35/2)*x2
  term2 <- (5/2)*x1*x2 + 19*x2^2
  term3 <- -(15/2)*x1^3 - (5/2)*x1*x2^2
  term4 <- -(11/2)*x2^4 + (x1^3)*(x2^2)

  y <- (9 + term1 + term2 + term3 + term4)*11/20
  return(y)
}

f2 <- function(x){
  5*exp(-((8*x[1]-2)^2 + (8*x[2] - 2)^2))*(8*x[1] - 2)
}

twin_galaxies <- function(x) f1(x) + f2(x)

xx <- seq(0, 1, length.out=51)
zz <- expand.grid(xx, xx)
yy <- matrix(apply(zz, 1, twin_galaxies), nrow=51)
image(yy, 
      col=colorRampPalette(rev(RColorBrewer::brewer.pal(11, "RdBu")))(100),
      xlab="x1", ylab="x2")
```

Next, we generate data using the computer model
```{R}
X <- lhs::maximinLHS(500, 2)
y <- apply(X, 1, twin_galaxies)

Xtest <- matrix(runif(2*50), ncol=2)
ytest <- apply(Xtest, 1, twin_galaxies)
```

## Standard Usage of leapgp
The standard leapgp algorithm has two tuning parameters. First, $M_0$ is the number of initial prediction hubs placed during the training phase and $\rho \in [0,1]$ is a parameter controlling the time-accuracy tradeoff. 
```{R}
tic()
mod <- leapGP(X, y, M0=30)
toc()

tic()
pred1 <- rep(NA, 50)
for(i in 1:50){
  mod <- predict_leapGP(mod, Xtest[i,], rho=0.95)
  pred1[i] <- mod$mean
}
toc()
plot(pred1, ytest, main=paste("RMSE = ", round(sqrt(mean((pred1-ytest)^2)), 4)))
abline(0, 1)
```

## leapgp without Training Step
It is possible to skip the training step for the `leapgp` algorithm. To do this, we simply initialize an empty model with
```{R}
tic()
mod <- leapGP(X, y, M0=0)
toc()
```
Then we can make sequential predictions as follows
```{R}
tic()
pred2 <- rep(NA, 50)
for(i in 1:50){
  mod <- predict_leapGP(mod, Xtest[i,], rho=0.95)
  pred2[i] <- mod$mean
}
toc()
plot(pred2, ytest, main=paste("RMSE = ", round(sqrt(mean((pred2-ytest)^2)), 4)))
```

## leapgp without Adaptation
One way to obtain extremely fast predictions is to use `leapgp` without adaptation. This is akin to setting $\rho = 0$. Note that prediction quality may suffer in this case, but it is often useful for rapid sequential emulation during development. 
```{R}
tic()
mod <- leapGP(X, y, M0=30)
toc()

tic()
pred3 <- rep(NA, 50)
for(i in 1:50){
  mod <- predict_leapGP(mod, Xtest[i,], rho=0)
  pred3[i] <- mod$mean
}
toc()
plot(pred3, ytest, main=paste("RMSE = ", round(sqrt(mean((pred3-ytest)^2)), 4)))
```

## leapgp with Uncertainty
If uncertainty surrounding predictions is desired, this can be easily obtained by setting `scale = TRUE`. This does lead to slightly slower emulation and more memory usage. 
```{R, eval=FALSE}

mod <- leapGP(X, y, M0=30, scale=TRUE)

pred <-  sd <- rep(NA, 50)
for(i in 1:50){
  mod <- predict_leapGP(mod, Xtest[i,], rho=0.95, scale=TRUE)
  pred[i] <- mod$mean
  sd[i] <- mod$sd
}
```


## leapgp Batch Prediction
Recall that `leapgp` was designed specifically for sequential emulation. The package does permit batch prediction, using 
```{R, eval=FALSE}
mod  <- leapGP(X, y, M0=30, scale=TRUE)
mod  <- predict_leapGP(mod, Xtest, rho=0.95, scale=TRUE)
pred <- mod$mean
sd   <- mod$sd
```
but there are likely better emulators available for such settings, especially if parallel computation is possible. 



